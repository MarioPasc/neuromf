# MeanFlow training config â€” best known architecture
# Full training configuration for MeanFlow on brain MRI latents.
#
# Architecture choices (proven in xpred_exact_jvp ablation, FID 14.4):
#   - x-prediction + exact JVP (stable; u-pred + FD-JVP diverges)
#   - (t, h) conditioning (MF Table 1c: FID 61.06 vs h-only 63.13)
#   - v-head with 1 ResBlock (tangent supervision + extra gradient signal)
#   - L2 loss (p=2) with adaptive weighting (norm_p=1, norm_eps=1)
#
# Picasso overlay overrides hardware settings (GPUs, batch, workers, augmentation).
# Ablation overlays override only what they test (inheriting everything else).

# Trainer infrastructure
# For multi-GPU DDP, override devices/strategy in picasso/train_meanflow.yaml
trainer:
  devices: 1          # Number of GPUs (1 = single-GPU, N = DDP with N GPUs)
  strategy: auto      # "auto" for single-GPU, "ddp" for multi-GPU
  accelerator: auto   # "auto" detects GPU/CPU, "gpu" to force CUDA

# Model
unet:
  spatial_dims: 3
  in_channels: 4
  out_channels: 4
  channels: [64, 128, 256, 512]
  attention_levels: [false, false, true, true]
  num_res_blocks: 2
  num_head_channels: [0, 0, 32, 32]
  norm_num_groups: 32
  resblock_updown: true
  transformer_num_layers: 1
  use_flash_attention: false           # must be false for exact JVP (torch.func.jvp)
  with_conditioning: false
  prediction_type: x                   # x-prediction (proven stable with exact JVP)
  t_min: 0.05
  gradient_checkpointing: false        # must be false for exact JVP (torch.func.jvp)
  use_v_head: true                     # iMF dual-head: v-head provides JVP tangent
  v_head_num_res_blocks: 1             # 1 ResBlock (~228K params)
  conditioning_mode: t_h               # MF Table 1c optimal: (t, h=t-r)

# Training
training:
  batch_size: 24
  lr: 1.0e-4
  weight_decay: 0
  optimizer: adamw
  betas: [0.9, 0.95]            # reference: adam_beta2=0.95
  max_epochs: 1500              # target ~61K optimizer steps on Picasso
  warmup_steps: 0               # reference: no warmup
  lr_schedule: cosine            # "constant" | "cosine" | "linear"
  gradient_clip_norm: 1.0
  gradient_checkpointing: false  # must be false for exact JVP
  mixed_precision: bf16
  log_every_n_steps: 50
  val_every_n_epochs: 10
  save_every_n_epochs: 50
  num_workers: 0
  prefetch_factor: null
  split_ratios: [0.85, 0.10, 0.05]  # train/val/test (stratified by dataset)
  split_seed: 42
  accumulate_grad_batches: 1      # gradient accumulation steps
  divergence_grace_steps: 1000    # skip first N steps for EMA warnings
  augmentation:                   # disabled for local dev; enabled in Picasso overlay
    enabled: false
    transforms:
      flip_d:                      # depth axis = L-R in RAS (approximately symmetric)
        prob: 0.5
      gaussian_noise:
        prob: 0.2
        std_fraction: 0.05        # 5% of per-channel std
      intensity_scale:
        prob: 0.2
        factors: 0.05             # +/-5% scaling

# MeanFlow
meanflow:
  p: 2.0
  adaptive: true
  norm_eps: 1.0                   # stability constant (Phase 4c fix)
  lambda_mf: 1.0
  prediction_type: x              # must match unet.prediction_type
  t_min: 0.05
  jvp_strategy: exact             # exact JVP via torch.func.jvp
  fd_step_size: 1.0e-3
  channel_weights: null
  norm_p: 1.0                     # adaptive weight exponent (1.0 = log-loss)
  spatial_mask_ratio: 0.0         # Phase C (0.0=off)
  use_v_head: true                # must match unet.use_v_head

# Time sampling
time_sampling:
  distribution: logit_normal
  mu: -0.4
  sigma: 1.0
  t_min: 0.001
  data_proportion: 0.5           # match iMF reference: 50% FM, 50% MF

# EMA
ema:
  decay: 0.9999

# Sampling / logging (legacy keys, kept for backward compat)
sample_every_n_epochs: 50
n_samples_per_log: 4
latent_spatial_size: 48

# Sample collection (replaces inline sample generation)
sample_collector:
  enabled: true
  collect_every_n_epochs: 50    # reduced for 1500-epoch training
  n_samples: 4
  nfe_steps: [1, 2, 5, 10]     # multi-NFE for comparison
  seed: 42                      # fixed noise for evolution tracking

# VAE for post-training decode (used by decode_samples.py CLI)
vae:
  spatial_dims: 3
  in_channels: 1
  out_channels: 1
  latent_channels: 4
  num_channels: [64, 128, 256]
  num_res_blocks: [2, 2, 2]
  norm_num_groups: 32
  norm_eps: 1.0e-6
  attention_levels: [false, false, false]
  with_encoder_nonlocal_attn: false
  with_decoder_nonlocal_attn: false
  use_checkpointing: false
  use_convtranspose: false
  norm_float16: false
  num_splits: 6
  dim_split: 1
  scale_factor: 0.96240234375
  downsample_factor: 4

# Evaluation (two-tier: SWD + 2.5D FID)
evaluation:
  enabled: false
  n_swd_samples: 64
  n_swd_projections: 128
  n_real_cache: 200
  n_fid_samples: 100
  n_fid_real_samples: 200
  fid_every_n_val_epochs: 3
  center_slices_ratio: 0.6
  fid_weights_path: ""
  early_stop_patience: 10
  seed: 42

# Diagnostics
diagnostics:
  enabled: false
  every_n_epochs: 50

# Paths (will be merged with base.yaml)
paths:
  latents_dir: ${paths.results_root}/latents
  checkpoints_dir: ${paths.results_root}/training_checkpoints
  logs_dir: ${paths.results_root}/phase_4/logs
  samples_dir: ${paths.results_root}/phase_4/samples
  diagnostics_dir: ${paths.results_root}/phase_4/diagnostics
